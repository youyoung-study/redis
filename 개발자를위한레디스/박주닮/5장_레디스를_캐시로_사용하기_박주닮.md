# 소개

---

레디스를 캐시로 사용하는 방법을 알아보고 캐시란 무엇인지, 어떤 상황에서 캐시를 사용해야 하는지, 레디스를 캐시로 잘 사용하는 방법과 주의해야 할 점까지 학습한다. 캐시와 비슷한 다른 세션 스토어에 대해서도 알아본다.

# 레디스와 캐시

---

### 캐시란?

캐시란 데이터의 원본보다 더 빠르고 효율적으로 액세스 할 수 있는 임시 데이터 저장소를 의미한다. 사용자가 동일한 정보를 반복적으로 액세스할 때 원본이 아니라 캐시에서 데이터를 가지고 옴으로써 리소스를 줄일 수 있다.

**캐시를 적용하기 위한 좋은 조건**

1. 원본 데이터 저장소에서 원하는 데이터를 찾기 위해 검색하는 시간이 오래걸리거나, 매번 계산을 통해 데이터를 가져와야 한다.
2. 캐시에서 데이터를 가져오는 것이 원본 데이터 저장소 데이터를 요청하는 것보다 빨라야 한다.
3. 캐시에 저장된 데이터는 잘 변하지 않는 데이터다.
4. 캐시에 저장된 데이터는 자주 검색되는 데이터다.

**위와 같은 상황에 맞을 경우 캐시를 활용하면 많은 문제점을 해결 할 수 있다.**

- 애플리케이션 응답 속도 단축
- 원본 데이터 저장소에서 데이터를 읽는 커넥션을 줄일 수 있다.
- CPU 메모리 등의 애플리케이션 자체의 리소스를 줄일 수 있다.
- 원본 데이터 저장소에 장애가 발생해도 캐시에서 데이터를 가지고 올 수 있다.

### Redis가 캐시 저장소로 이상적인 이유

**1. Redis는 사용이 간단합니다.**

단순하게 키-값 형태로 저장하므로, 데이터를 저장하고 반환하는 것이 굉장히 간단하며, 자체적으로 다양한 자료 구조를 제공하기 때문에 애플리케이션에서 사용하던 list, hash 등의 자료 구조를 변환하는 과정 없이 레디스에 바로 저장할 수 있습니다.

**2. Redis는 모든 데이터를 메모리에 저장하는 인메모리 데이터 저장소로, 데이터 검색과 반환 속도가 매우 빠릅니다.**

관계형 데이터베이스(RDBMS)는 디스크에 데이터를 저장하기 때문에, 데이터를 조회할 때 디스크 I/O 작업이 필요합니다. 디스크는 물리적인 장치를 기반으로 하기 때문에 데이터를 읽고 쓰는 데 시간이 더 많이 소요됩니다. 반면, Redis는 데이터를 메모리에 저장하므로 디스크 접근이 필요하지 않으며, 평균 읽기 및 쓰기 속도가 1ms 미만으로 유지됩니다.

메모리가 디스크보다 빠른 이유는 두 가지입니다.

첫째, 물리적 제약이 없습니다. 디스크는 데이터를 읽기 위해 회전하는 플래터와 움직이는 헤드를 사용하므로 탐색 시간이 필요합니다. 반면, 메모리는 전기 신호로 데이터를 처리하기 때문에 데이터 접근이 훨씬 빠릅니다.

둘째, I/O 병목 현상이 최소화됩니다. 디스크 기반 시스템은 많은 데이터를 동시에 처리할 때 병목 현상이 발생할 수 있지만, 메모리는 이러한 병목 현상이 거의 없어 Redis는 수백만 건의 작업을 초당 처리할 수 있습니다.

이러한 특성 덕분에 Redis는 세션 관리, 실시간 애플리케이션, 캐싱, 랭킹 서비스 등 데이터 접근 속도가 중요한 시스템에서 널리 활용됩니다. Redis를 캐시 저장소로 도입하면 시스템 성능을 크게 향상시킬 수 있습니다.

**3.  Redis는 자체적으로 고가용성 기능을 가지고 있는 솔루션입니다.**

일부 캐싱 전략에서는 캐시에 접근할 수 없게 되면 이는 곧바로 서비스의 장애로 이어질 수도 있습니다. 따라서 캐시 저장소도 일반적인 데이터 저장소와 같이 안정적으로 운영될 수 있는 조건을 갖추는 것이 좋습니다. 레디스의 센티널 또는 클러스터 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 페일오버를 발생시키기 때문에 운영자의 개입 없이 캐시는 정상으로 유지될 수 있어 가용성이 높아집니다.

# 레디스의 캐싱 전략

---

### 읽기 전략 - look aside

애플리케이션에서 데이터를 읽어갈 때 주로 사용함

가장 일반적인 배치 방법

1. 애플리케이션은 찾고자 하는 데이터가 먼저 캐시에 있는지를 확인
2. 캐시에 데이터가 있으면 캐시에서 데이터를 읽어온다(캐시 히트)
3. 캐시에 데이터가 없으면(캐시 미스) 데이터베이스에 접근해 찾고자 하는 데이터를 가져온다. 그 뒤 다시 캐시에 저장한다.

**장점**

- 레디스에 문제가 생겨 접근을 할 수 없는 상황이 발생하더라도 바로 서비스 장애로 이어지지 않고 데이터베이스에서 데이터를 가지고 올 수 있다.

**단점**

- 레디스를 통해 데이터를 가져오는 연결이 매우 많았다면 모든 커넥션이 한꺼번에 원본 데이터베이스로 몰려 많은 부하를 발생시키고, 이로 인해 원본 데이터베이스의 응답이 느려지거나 리소스를 많이 차지하는 등의 이슈가 발생해 애플리케이션의 성능에 영향을 미칠 수 있다.

# 캐시 불일치

---

만약 데이터가 변경될 때 원본 데이터베이스에만 업데이트돼 캐시에는 변경된 값이 반영되지 않는다면 데이터 간 불일치가 일어난다. 이를 캐시 불일치라 한다.

### 캐시를 이요한 쓰기 전략 세가지

1. write through
    - 데이터베이스에 업데이트할 때마다 매번 캐시에도 데이터를 함께 업데이트 시키는 전략
    - 매번 2개의 저장소에 저장돼야 하기 때문에 데이터를 쓸 때마다 시간이 많이 소요될 수 있다는 단점
2. cache invalidation
    - 데이트베이스에 값을 업데이트할 때마다 캐시에서는 데이터를 삭제하는 전략
    - 저장소에서 특정 데이터를 삭제하는 것이 새로운 데이터를 저장하는 것보다 훨씬 리소스를 적게 사용하기 때문에 앞선 write through의 단점을 보완한 방법
3. write behind(write back)
    - 대용량 데이터 처리 시 먼저 데이터를 빠르게 접근할 수 있는 캐시에 업데이트한 뒤, 이후에는 건수나 특정 시간 간격 등에 따라 비동기적으로 데이터베이스에 업데이트하는 전략
    - 캐시에 문제가 생겨 데이터가 날아갈 경우 최대 5분 동안의 데이터가 날아갈 수 있는 위험성이 존재

# 캐시에서의 데이터 흐름

---

메모리의 용량을 초과하는 양의 데이터가 저장되면 레디스는 내부 정책을 사용해 어떤 키를 삭제할지 결정한다.

레디스에서는 데이터의 최대 저장 용량을 설정하는 maxmemory설정과 이 용량을 초과할 때의 처리 방식을 결정하는 maxmemory-policy 설정값을 사용해 메모리를 관리한다.

### maxmemory-policy 설정

### Noeviction

- 기본값
- 레디스에 데이터가 가득 차더라도 임의로 데이터를 삭제하지 않고 더 이상 레디스에 데이터를 저장할 수 없다는 에러를 반환하는 설정 값
- 레디스를 캐시로 사용할 때 권장하지 않음
    - 캐시에 데이터를 저장하지 못해 에러가 발생할 경우 로직에 따라 장애 상황으로 이어질 수 있다.
    - 관리자가 레디스의 데이터를 직접 지워야 하기 때문이다.
- 데이터의 관리를 캐시에게 맡기지 않고 직접 관리하겠다는 것을 의미한다.

### LRU(Least-Recently Used) eviction

- 데이터가 가득 찼을 때 가장 최근에 사용되지 않은 데이터부터 삭제하는 정책
- 최근에 액세스되지 않은 데이터는 나중에도 액세스될 가능성이 낮을 것이라는 가정을 전제
- LRU 알고리즘을 이용한 두 가지 설정값
    - volatile-lru
        - 만료 시간이 설정돼 있는 키에 한해서 LRU 방식으로 키를 삭제한다.
        - 만료 시간이 설정돼 있는 키는 언젠가 삭제될 키라는 것을 의미하기 때문에 이런 키 중 가장 오래 사용되지 않은 키를 삭제하는 방식
        - 단 TTL이 설정되어 있지 않다면 기본값과 다를 바가 없어짐(주의)
    - allkeys-LRU
        - 레디스 공식 문서에서는 레디스를 캐시로 사용할 경우, 잘 모르겠다면 이 방식을 사용하기를 권장
        - 모든 키에 대해 LRU 알고리즘을 이용해 데이터를 삭제하기 때문에 적어도 메모리가 꽉 찼을 때 장애가 발생할 상황은 방지

### LFU(Least-Frequently Used) eviction

- 데이터가 가득 찼을 때 가장 자주 사용되지 않은 데이터부터 삭제하는 정책
- 자주 사용되지 않은 데이터는 나중에도 액세스될 가능성이 낮을 것이라는 가정을 전제
- 키가 오랫동안 사용되지 않았더라도 과거에 자주 액세스했던 키라면 나중에도 자주 사용될 수 있다는 가정하에 우선순위가 높아지게 된다.
- LFU 알고리즘을 이용한 두 가지 설정 값
    - volatile-lfu
        - 만료 시간이 설정돼 있는 키에 한해서 LFU 방식으로 키를 삭제한다.
    - allkeys-lfu
        - 모든 키에 대해 LFU 알고리즘을 이용해 데이터를 삭제한다.

### RANDOM eviction

- 랜덤으로 데이터를 삭제하기 때문에 권장하지 않음

# 캐시 스탬피드 현상

---

레디스에서 특정 키가 만료되는 시점에 여러 개의 애플리케이션에서 데이터를 요청하면 한꺼번에 데이터베이스에 가서 데이터를 읽어오는 중복 읽기 발생.

이후 각 애플리케이션에서는 읽어온 데이터를 레디스에 쓰는 중복 쓰기가 발생.

# 해결 방법

---

### 적절한 만료 시간 설정

- 만료시간을 너무 짧지 않게 설정하는것

### 선 계산

- 키가 실제로 만료되기 전에 이 값을 미리 갱신해준다면 여러 애플리케이션에서 한꺼번에 데이터베이스에 접근해 데이터를 읽어오는 과정을 줄여 불필요한 프로세스를 줄일 수 있다.

### PER 알고리즘

- 2015년에 캐시 스탬피드 현상을 완화시킬 수 있는 확률적 조기 재계싼 알고리즘이 연구됨
- 캐시 값이 만료되기 전에 언제 데이터베이스에 접근해서 값을 읽어오면 되는지 최적으로 계산 가능

```java
currentTime - ( timeToCompute * beta * log(rand()) ) > expiry
```

- currentTime : 현재 남은 만료시간
- timeToCompute : 캐시된 값을 다시 계산하는데 걸리는 시간
- beta : 기본적으로 1.0보다 큰 값으로 설정 가능
- rand(): 0 관 1 사이의 랜덤 값을 반환하는 함수
- expiry : 키를 재설정할 때 새로 넣어줄 만료 시간
- 만료시간에 가까워질수록 true를 반환할 확률이 증가
